{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T07:07:51.699769Z",
     "start_time": "2020-12-18T07:07:51.072715Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "from models import *\n",
    "from utils.utils import *\n",
    "from utils.datasets import *\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "import argparse\n",
    "import cv2\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.ticker import NullLocator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arg Parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T07:07:51.703729Z",
     "start_time": "2020-12-18T07:07:51.700717Z"
    }
   },
   "outputs": [],
   "source": [
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument(\"--image_folder\", type=str, default=\"data/samples\", help=\"path to dataset\")\n",
    "# parser.add_argument(\"--model_def\", type=str, default=\"config/yolov3.cfg\", help=\"path to model definition file\")\n",
    "# parser.add_argument(\"--weights_path\", type=str, default=\"weights/yolov3.weights\", help=\"path to weights file\")\n",
    "# parser.add_argument(\"--class_path\", type=str, default=\"data/coco.names\", help=\"path to class label file\")\n",
    "# parser.add_argument(\"--conf_thres\", type=float, default=0.8, help=\"object confidence threshold\")\n",
    "# parser.add_argument(\"--nms_thres\", type=float, default=0.4, help=\"iou thresshold for non-maximum suppression\")\n",
    "# parser.add_argument(\"--batch_size\", type=int, default=1, help=\"size of the batches\")\n",
    "# parser.add_argument(\"--n_cpu\", type=int, default=0, help=\"number of cpu threads to use during batch generation\")\n",
    "# parser.add_argument(\"--img_size\", type=int, default=416, help=\"size of each image dimension\")\n",
    "# parser.add_argument(\"--checkpoint_model\", type=str, help=\"path to checkpoint model\")\n",
    "# opt = parser.parse_args()\n",
    "# print(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T07:07:51.710729Z",
     "start_time": "2020-12-18T07:07:51.704716Z"
    }
   },
   "outputs": [],
   "source": [
    "class opt:\n",
    "    image_folder = \"data/samples\"\n",
    "    model_def = \"config/yolov3.cfg\"\n",
    "    weights_path = \"weights/yolov3.weights\"\n",
    "    class_path = \"data/coco.names\"\n",
    "    conf_thres = 0.8\n",
    "    nms_thres = 0.4\n",
    "    batch_size = 1\n",
    "    n_cpu = 0\n",
    "    img_size = 416\n",
    "    checkpoint_model= str()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T07:07:51.716717Z",
     "start_time": "2020-12-18T07:07:51.711718Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_one_box(x, img, color=1, label=None, line_thickness=None):\n",
    "    # Plots one bounding box on image img\n",
    "    tl = line_thickness or round(0.002 * (img.shape[0] + img.shape[1]) / 2) + 1  # line/font thickness\n",
    "    color = color or [random.randint(0, 255) for _ in range(3)]\n",
    "    c1, c2 = (int(x[0]), int(x[1])), (int(x[2]), int(x[3]))\n",
    "    cv2.rectangle(img, c1, c2, color, thickness=tl, lineType=cv2.LINE_AA)\n",
    "    if label:\n",
    "        tf = max(tl - 1, 1)  # font thickness\n",
    "        t_size = cv2.getTextSize(label, 0, fontScale=tl / 3, thickness=tf)[0]\n",
    "        c2 = c1[0] + t_size[0], c1[1] - t_size[1] - 3\n",
    "        cv2.rectangle(img, c1, c2, color, -1, cv2.LINE_AA)  # filled\n",
    "        cv2.putText(img, label, (c1[0], c1[1] - 2), 0, tl / 3, [225, 255, 255], thickness=tf, lineType=cv2.LINE_AA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T07:07:51.722715Z",
     "start_time": "2020-12-18T07:07:51.717716Z"
    }
   },
   "outputs": [],
   "source": [
    "def figure_to_array(fig):\n",
    "    \"\"\"\n",
    "    plt.figure를 RGBA로 변환(layer가 4개)\n",
    "    shape: height, width, layer\n",
    "    \"\"\"\n",
    "    fig.canvas.draw()\n",
    "    return np.array(fig.canvas.renderer._renderer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T07:07:53.373747Z",
     "start_time": "2020-12-18T07:07:51.723717Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "os.makedirs(\"output\", exist_ok=True)\n",
    "\n",
    "# Set up model\n",
    "model = Darknet(opt.model_def, img_size=opt.img_size).to(device)\n",
    "\n",
    "if opt.weights_path.endswith(\".weights\"):\n",
    "    # Load darknet weights\n",
    "    model.load_darknet_weights(opt.weights_path)\n",
    "else:\n",
    "    # Load checkpoint weights\n",
    "    model.load_state_dict(torch.load(opt.weights_path))\n",
    "\n",
    "model.eval()  # Set in evaluation mode\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    ImageFolder(opt.image_folder, img_size=opt.img_size),\n",
    "    batch_size=opt.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=opt.n_cpu,\n",
    ")\n",
    "\n",
    "classes = load_classes(opt.class_path)  # Extracts class labels from file\n",
    "\n",
    "Tensor = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor\n",
    "\n",
    "imgs = []  # Stores image paths\n",
    "img_detections = []  # Stores detections for each image index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Webcam Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T07:07:55.963125Z",
     "start_time": "2020-12-18T07:07:53.374737Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "width = 1280\n",
    "height = 720\n",
    "\n",
    "cam = cv2.VideoCapture(0)\n",
    "cam.set(3, width)\n",
    "cam.set(4, height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T07:09:33.101234Z",
     "start_time": "2020-12-18T07:07:55.965095Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPS of the video is  0.86\n",
      "FPS of the video is 26.38\n",
      "FPS of the video is 27.68\n",
      "FPS of the video is 27.75\n",
      "FPS of the video is 29.04\n",
      "FPS of the video is 28.40\n",
      "FPS of the video is 28.76\n",
      "FPS of the video is 28.21\n",
      "FPS of the video is 27.86\n",
      "FPS of the video is 27.16\n",
      "FPS of the video is 27.75\n",
      "FPS of the video is 29.20\n",
      "FPS of the video is 29.01\n",
      "FPS of the video is 28.87\n",
      "FPS of the video is 27.51\n",
      "FPS of the video is 27.88\n",
      "FPS of the video is 27.19\n",
      "FPS of the video is 29.01\n",
      "FPS of the video is 29.04\n",
      "FPS of the video is 29.17\n",
      "FPS of the video is 27.86\n",
      "FPS of the video is 27.66\n",
      "FPS of the video is 27.21\n",
      "FPS of the video is 27.98\n",
      "FPS of the video is 28.54\n",
      "FPS of the video is 28.35\n",
      "FPS of the video is 28.52\n",
      "FPS of the video is 27.13\n",
      "FPS of the video is 27.78\n",
      "FPS of the video is 26.92\n",
      "FPS of the video is 28.60\n",
      "FPS of the video is 28.54\n",
      "FPS of the video is 28.38\n",
      "FPS of the video is 28.58\n",
      "FPS of the video is 26.57\n",
      "FPS of the video is 27.65\n",
      "FPS of the video is 27.86\n",
      "FPS of the video is 28.77\n",
      "FPS of the video is 28.68\n",
      "FPS of the video is 28.77\n",
      "FPS of the video is 27.42\n",
      "FPS of the video is 27.72\n",
      "FPS of the video is 27.08\n",
      "FPS of the video is 28.43\n",
      "FPS of the video is 28.48\n",
      "FPS of the video is 28.35\n",
      "FPS of the video is 28.60\n",
      "FPS of the video is 26.73\n",
      "FPS of the video is 27.66\n",
      "FPS of the video is 27.68\n",
      "FPS of the video is 28.35\n",
      "FPS of the video is 28.45\n",
      "FPS of the video is 28.78\n",
      "FPS of the video is 27.17\n",
      "FPS of the video is 27.78\n",
      "FPS of the video is 27.10\n",
      "FPS of the video is 28.54\n",
      "FPS of the video is 28.57\n",
      "FPS of the video is 28.97\n",
      "FPS of the video is 28.41\n",
      "FPS of the video is 26.20\n",
      "FPS of the video is 27.68\n",
      "FPS of the video is 27.65\n",
      "FPS of the video is 28.80\n",
      "FPS of the video is 28.91\n",
      "FPS of the video is 28.15\n",
      "FPS of the video is 28.07\n",
      "FPS of the video is 27.77\n",
      "FPS of the video is 26.94\n",
      "FPS of the video is 28.55\n",
      "FPS of the video is 29.04\n",
      "FPS of the video is 29.26\n",
      "FPS of the video is 28.88\n",
      "FPS of the video is 26.75\n",
      "FPS of the video is 27.67\n",
      "FPS of the video is 27.37\n",
      "FPS of the video is 29.15\n",
      "FPS of the video is 28.46\n",
      "FPS of the video is 28.62\n",
      "FPS of the video is 27.91\n",
      "FPS of the video is 27.75\n",
      "FPS of the video is 27.11\n",
      "FPS of the video is 28.35\n",
      "FPS of the video is 29.10\n",
      "FPS of the video is 28.94\n",
      "FPS of the video is 28.88\n",
      "FPS of the video is 27.28\n",
      "FPS of the video is 27.71\n",
      "FPS of the video is 27.42\n",
      "FPS of the video is 29.03\n",
      "FPS of the video is 28.58\n",
      "FPS of the video is 28.50\n",
      "FPS of the video is 28.81\n",
      "FPS of the video is 27.26\n"
     ]
    }
   ],
   "source": [
    "# Bounding-box colors\n",
    "frames = 0\n",
    "start = time.time()\n",
    "\n",
    "# ret_val, img = cam.read()\n",
    "# img_size = img.shape[:2]\n",
    "\n",
    "while True:\n",
    "    ret_val, img = cam.read()\n",
    "    # img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    # Mirror \n",
    "    img = cv2.flip(img, 1)\n",
    "    img_re = cv2.resize(img, (416, 416))\n",
    "    \n",
    "    input_imgs = transforms.ToTensor()(img_re)\n",
    "    input_imgs = torch.unsqueeze(input_imgs, 0).cuda()\n",
    "\n",
    "    # Get detections\n",
    "    with torch.no_grad():\n",
    "        detections = model(input_imgs)\n",
    "        detections = non_max_suppression(detections, opt.conf_thres, opt.nms_thres)\n",
    "        img_detections.extend(detections)\n",
    "    \n",
    "    # Create plot\n",
    "    # Draw bounding boxes and labels of detections\n",
    "    if detections[0] is not None:\n",
    "        # Rescale boxes to original image\n",
    "        detections = rescale_boxes(detections[0], opt.img_size, img.shape[:2])\n",
    "\n",
    "        for x1, y1, x2, y2, conf, cls_conf, cls_pred in detections:\n",
    "            plot_one_box((x1,y1,x2,y2), img, label=classes[int(cls_pred)])\n",
    "    \n",
    "    frames += 1\n",
    "    intv = time.time() - start\n",
    "    if intv > 1:\n",
    "        print(\"FPS of the video is {:5.2f}\".format( frames / intv ))\n",
    "#         print(detections)\n",
    "        start = time.time()\n",
    "        frames = 0\n",
    "    \n",
    "    cv2.imshow('Demo webcam', img)\n",
    "    if cv2.waitKey(1) == 27: \n",
    "        break  # esc to quit\n",
    "        \n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
